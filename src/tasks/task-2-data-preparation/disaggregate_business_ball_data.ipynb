{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# import sklearn.feature_extraction.text as txt\n",
        "import bs4\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "import datetime"
      ],
      "metadata": {
        "id": "OpYlaDWxNxyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXFPLKBaIwQ1"
      },
      "outputs": [],
      "source": [
        "# read business_ball data\n",
        "file_path = '/content/businessballs_data.csv'\n",
        "businessballs_data = pd.read_csv(file_path)\n",
        "businessballs_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "businessballs_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp9B7shbOTMw",
        "outputId": "20e160b0-6a03-4657-cba0-546ce96e869e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 177 entries, 0 to 176\n",
            "Data columns (total 12 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Unnamed: 0     177 non-null    int64  \n",
            " 1   skill          177 non-null    object \n",
            " 2   title          177 non-null    object \n",
            " 3   reading_time   177 non-null    object \n",
            " 4   rating         177 non-null    float64\n",
            " 5   views          177 non-null    object \n",
            " 6   link           177 non-null    object \n",
            " 7   body           177 non-null    object \n",
            " 8   raw_body_data  177 non-null    object \n",
            " 9   metadata       177 non-null    object \n",
            " 10  tracking_log   177 non-null    object \n",
            " 11  validator_log  177 non-null    object \n",
            "dtypes: float64(1), int64(1), object(10)\n",
            "memory usage: 16.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this function disaggregates the content column (html format) of the df dataframe into many paragraphs\n",
        "# For each paragraph, it searchs for the first previous heading found\n",
        "\n",
        "#**************************************************************************************\n",
        "# to save memory the Content and paragraphs will be droped from the returned dataframe\n",
        "#**************************************************************************************\n",
        "\n",
        "def disaggregate_content(df, tag = 'p', a_class = None): # df is supposed a dataframe that contains the Content column in the html format : <body>....</body>\n",
        "    # these list are used to constract the returned dataframe\n",
        "    soft_kill_names_df = [] # \n",
        "    criterias_df = [] \n",
        "    URLs_df = []\n",
        "    titles_of_URLs_df = []\n",
        "    summaries_df = [] # summary produced in the previous step (summary of all the concateneted paragraphs)\n",
        "    paragraphs_df = []\n",
        "    headings_df = [] # heading just before paragraph\n",
        "    headings_type_df = [] # type of tytle : h1, h2,...\n",
        "    \n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        soup = bs4.BeautifulSoup(row['raw_body_data'], \"html.parser\")\n",
        "        \n",
        "        if a_class != None:\n",
        "            paragraphs = soup.find_all(tag, a_class) \n",
        "        else:\n",
        "            paragraphs = soup.find_all(tag) \n",
        "            \n",
        "        for paragraph in paragraphs:\n",
        "            \n",
        "            # get paragraph text\n",
        "            temp = paragraph.get_text()\n",
        "            if temp == '': # if empty we continue\n",
        "                continue\n",
        "            \n",
        "            paragraphs_df.append(paragraph.get_text())\n",
        "            \n",
        "            # get the old columns of df except Content beacause it's huge and we won't need it later\n",
        "            soft_kill_names_df.append(row['skill']) \n",
        "            # criterias_df.append(row['Criteria']) \n",
        "            URLs_df.append(row['link'])\n",
        "            titles_of_URLs_df.append(row['title'])\n",
        "            # summaries_df.append(row['summary'])\n",
        "            \n",
        "            # find heading just before that paragraph. find_heading returns (title, hx). See definition below\n",
        "            heading = find_heading(paragraph)\n",
        "            headings_df.append(heading[0]) # the text heading\n",
        "            try:\n",
        "                # it's type : h1...h6\n",
        "                headings_type_df.append(heading[1])\n",
        "            except:\n",
        "                # if no heading found affect None\n",
        "                headings_type_df.append('None')\n",
        "                continue\n",
        "        \n",
        "    \n",
        "    disaggregated_df = pd.DataFrame.from_dict({'Soft Skill Name' : soft_kill_names_df, \n",
        "                                               'URL': URLs_df, \n",
        "                                               'Title of URL' : titles_of_URLs_df, \n",
        "                                               'header':headings_df,\n",
        "                                                'paragraph' : paragraphs_df})\n",
        "    return disaggregated_df\n",
        "\n",
        "\n",
        "\n",
        "# this function looks for the first heading previous to elt passed as parameter\n",
        "# starting form h6 until h1\n",
        "def find_heading(elt):\n",
        "    headings = ['h6', 'h5', 'h4', 'h3', 'h2', 'h1']\n",
        "    elt = elt.previous_element\n",
        "    while (not (elt is None) ) and (not (elt.name in headings)):\n",
        "         elt = elt.previous_element\n",
        "    \n",
        "    if (not (elt is None) ):\n",
        "        return elt.get_text(), elt.name\n",
        "    else:\n",
        "        return 'None', 'None'"
      ],
      "metadata": {
        "id": "ibFXKvlwNZ-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "businessballs_data_disagg = disaggregate_content(businessballs_data, tag='p')"
      ],
      "metadata": {
        "id": "_ZvcQ0F9Na-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "businessballs_data_disagg.to_csv('businessballs_data_disagg.csv', index = False)\n",
        "businessballs_data_disagg.to_excel('businessballs_data_disagg.xlsx', index = False)"
      ],
      "metadata": {
        "id": "bIByfxFyQXJ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}